Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/8d3e5006-dba1-4834-9b43-c0cd18b1f201
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.076021 | mean episode length: 19.762376
ERROR 'avg_kl'
Process Process-10:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/55f85a7e-0d89-424a-acc5-11549c55c2fa
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.324941 | mean episode length: 19.578431
ERROR 'avg_kl'
Process Process-6:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/1aca99db-8f5e-4a8b-bd54-0189297d73f4
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.497368 | mean episode length: 19.568627
ERROR 'avg_kl'
Process Process-3:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/cecec7ad-d38b-45cc-88e3-ad488ccad46f
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.409525 | mean episode length: 20.171717
ERROR 'avg_kl'
Process Process-1:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/d378da1b-1db1-4b7b-ad3f-2790896413e2
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.351399 | mean episode length: 19.772277
ERROR 'avg_kl'
Process Process-2:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/fa048c1e-973c-410d-a678-2fbd49e6d7f9
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.104960 | mean episode length: 19.578431
ERROR 'avg_kl'
Process Process-5:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/2e879bfc-2a0f-4d90-8318-42f0e3d3edde
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.313471 | mean episode length: 19.970000
ERROR 'avg_kl'
Process Process-20:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/3565b878-4812-4862-ae2c-2a07230a2a16
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.445684 | mean episode length: 19.762376
ERROR 'avg_kl'
Process Process-7:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/72548c21-68cc-44ce-8cc4-aad05a242b05
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.255412 | mean episode length: 19.970000
ERROR 'avg_kl'
Process Process-8:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/ba243c9d-404a-42d7-928c-ba6b0fab85fb
Step 0
--------------------------------------------------------------------------------
Current mean reward: -0.179164 | mean episode length: 19.378641
ERROR 'avg_kl'
Process Process-4:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/d5677b54-37c8-41fe-96f4-fed6302426fb
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.133357 | mean episode length: 19.019048
ERROR 'avg_kl'
Process Process-24:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/a1ebb702-6fd3-44b2-b3fa-95d33c82731d
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.046141 | mean episode length: 20.171717
ERROR 'avg_kl'
Process Process-12:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/3f26e1ac-95f7-4896-a93c-43850e711765
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.596106 | mean episode length: 19.772277
ERROR 'avg_kl'
Process Process-17:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/40a39ae0-8afa-452f-b98f-0a1f69b9f018
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.318836 | mean episode length: 19.578431
ERROR 'avg_kl'
Process Process-19:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/1fde04c0-6720-4684-b38e-8085711df92a
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.322933 | mean episode length: 20.161616
ERROR 'avg_kl'
Process Process-11:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/e6135291-e95a-4576-a86a-49e1e8cb8f73
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.021268 | mean episode length: 19.388350
ERROR 'avg_kl'
Process Process-13:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/a8c47620-b127-43c2-a1cb-a31cedb7dc76
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.205631 | mean episode length: 19.970000
ERROR 'avg_kl'
Process Process-22:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/80d6c676-a7b1-4c13-b6ca-88af433c2be0
Step 0
--------------------------------------------------------------------------------
Current mean reward: -0.033308 | mean episode length: 19.970000
ERROR 'avg_kl'
Process Process-14:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/98f2c50f-aaa3-4c2f-a24e-11c37640593d
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.216402 | mean episode length: 19.578431
ERROR 'avg_kl'
Process Process-16:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/276b6ffc-ca9b-4bc3-a8f7-7995c3248a16
Step 0
--------------------------------------------------------------------------------
Current mean reward: -0.021106 | mean episode length: 19.388350
ERROR 'avg_kl'
Process Process-9:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/62a2ce14-9eb3-414b-b5bb-34ff13e2a728
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.048401 | mean episode length: 20.171717
ERROR 'avg_kl'
Process Process-15:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/a7f412e6-3c35-4a54-a0de-1d48ce7c5065
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.029744 | mean episode length: 20.171717
ERROR 'avg_kl'
Process Process-18:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/938da692-c03a-4f4f-a087-04680e38d45b
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.210527 | mean episode length: 19.578431
ERROR 'avg_kl'
Process Process-21:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_and_clip_experiment/agents/1c4ab510-55f0-4d9a-ad8d-f234f2c704ba
Step 0
--------------------------------------------------------------------------------
Current mean reward: 0.135900 | mean episode length: 19.578431
ERROR 'avg_kl'
Process Process-23:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 486, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 461, in take_steps
    table='paper_constraints_train')
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/logging.py", line 34, in paper_constraints_logging
    agent.store.log_table_and_tb(table, row)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 195, in log_table_and_tb
    update_dict = _clean_dict(update_dict, table.schema)
  File "/home/eecs/chloehsu/.local/lib/python3.6/site-packages/cox/store.py", line 448, in _clean_dict
    v_type = schema[k]
KeyError: 'avg_kl'
