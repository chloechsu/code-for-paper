Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/6de7f710-bd1b-48bf-a2bc-1063397a0a23
ERROR 'anneal_kl_penalty_coeff'
Process Process-5:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/3e1314b6-fd99-4c0f-8d05-62ee419fca4f
ERROR 'anneal_kl_penalty_coeff'
Process Process-13:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/69321448-c1f8-4b67-ab4f-3c605978f626
ERROR 'anneal_kl_penalty_coeff'
Process Process-12:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/775c0c6c-42da-4698-9614-fc62e68de7e8
ERROR 'anneal_kl_penalty_coeff'
Process Process-19:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/8666e809-b9c7-4bcc-9f00-02b989536057
ERROR 'anneal_kl_penalty_coeff'
Process Process-3:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/e792b29a-e4eb-42a3-aa67-2430b007e2f2
ERROR 'anneal_kl_penalty_coeff'
Process Process-23:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/2689ea86-4d43-4981-9e1e-d3b3ff8e0d32
ERROR 'anneal_kl_penalty_coeff'
Process Process-10:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/41ea4a7a-6ea5-4264-b3f1-d5382299b861
ERROR 'anneal_kl_penalty_coeff'
Process Process-11:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/bd774694-1702-4712-8783-00a5e8ee82d0
ERROR 'anneal_kl_penalty_coeff'
Process Process-24:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/b3533adc-9bc7-4fab-8571-6408dc162013
ERROR 'anneal_kl_penalty_coeff'
Process Process-21:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/23429180-2749-4f1f-b4e7-d42e1c5cce62
ERROR 'anneal_kl_penalty_coeff'
Process Process-9:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/ceba6202-7f4f-40f4-8cd3-5acb4cea102c
ERROR 'anneal_kl_penalty_coeff'
Process Process-6:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/a5ab870c-4621-4084-99a4-61c023bb392f
ERROR 'anneal_kl_penalty_coeff'
Process Process-7:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/aac2bf2c-e462-4343-aa18-a64888435b0b
ERROR 'anneal_kl_penalty_coeff'
Process Process-20:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/6d287ef2-880e-4f96-b80a-5720f9ac708f
ERROR 'anneal_kl_penalty_coeff'
Process Process-18:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/7246f6e2-9733-44a0-aece-ad661e23579b
ERROR 'anneal_kl_penalty_coeff'
Process Process-16:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/b2b66577-09e6-46f7-88d1-71c7b7cc557a
ERROR 'anneal_kl_penalty_coeff'
Process Process-14:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/126d335c-38e1-474e-bc9c-ed3743a0e072
ERROR 'anneal_kl_penalty_coeff'
Process Process-2:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/ba2a733a-c0e1-431d-8774-02d2322d4250
ERROR 'anneal_kl_penalty_coeff'
Process Process-8:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/56bc9eae-4374-4076-ab4f-0faf85f2a3e0
ERROR 'anneal_kl_penalty_coeff'
Process Process-15:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/35b1ae19-1c72-4b38-9d7f-d32ee575e690
ERROR 'anneal_kl_penalty_coeff'
Process Process-22:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/2c416cde-a769-4f74-a7c0-fc193c204b0f
ERROR 'anneal_kl_penalty_coeff'
Process Process-17:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/5280a7d1-ab77-44c1-98b4-268672c409fd
ERROR 'anneal_kl_penalty_coeff'
Process Process-1:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
Logging in: /home/eecs/chloehsu/ppo_ablation/code-for-paper/src/kl_vs_no_kl_experiment/agents/4a4e0bed-628a-44c4-8e8c-693688db8f82
ERROR 'anneal_kl_penalty_coeff'
Process Process-4:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "run_agents.py", line 20, in run_single_config
    raise e
  File "run_agents.py", line 17, in run_single_config
    main(params)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/run.py", line 119, in main
    mean_reward = p.train_step()
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 493, in train_step
    surr_loss, val_loss = self.take_steps(saps)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 462, in take_steps
    if self.ANNEAL_KL_PENALTY_COEFF:
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/agent.py", line 154, in __getattr__
    return getattr(self.params, x)
  File "/home/eecs/chloehsu/ppo_ablation/code-for-paper/src/policy_gradients/torch_utils.py", line 35, in __getattr__
    return self.params[x.lower()]
KeyError: 'anneal_kl_penalty_coeff'
